---
title: "Assignment"
author: "Group "
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---
Library and data Loading
```{r, warning=FALSE, message=FALSE}
#install.packages("psych")
library(caret)
library(class)
library(psych)
library(AdaSampling)
library(gbm)
train_cli <- read.table("../data/data/train_cli.tsv", header=T)
train_pro <- t(read.table("../data/data/train_pro.tsv", header=T))
test_cli <- read.table("../data/data/test_cli.tsv", header=T)
test_pro <- t(read.table("../data/data/test_pro.tsv", header=T))
is_correcrt_label <- read.table("../data/data/sum_tab_1.csv",sep=',', header=T)
```

###Basic statistics
#Calculate sensitivity, specificity, F1 score, geometric mean, accuracy
```{r, warning=FALSE, message=FALSE}
# sensitivity
evaluate <- function(TN, FP, TP, FN) {
  TN = sum(TN)
  FP = sum(FP)
  TP = sum(TP)
  FN = sum(FN)
  sensitivity = TP/(TP+FN)
  specificity = TN/(FP+TN)
  f1 = 2*TP/(2*TP+FP+FN)
  gmean = sqrt((TP/(TP+FN))*(TP/(TP+FP)))
  accuracy = (TP+TN)/(TP+FN+FP+TN)
  return(c(sensitivity, specificity, f1, gmean, accuracy))
}
```

#Check the number of NA and 0 of each line
```{r, warning=FALSE, message=FALSE}
Check_NA_0 <- function(feature){
  print("Total NA: ")
  num_NA = sum(is.na(feature))
  print(num_NA)
  feature = Replace_0(feature)
  print("Total 0: ")
  print(sum(feature ==0)-num_NA)
}
```

#Check the number of NA for each line
```{r, warning=FALSE, message=FALSE}
Check_NA_each_line <- function(feature){
  for (line in 1:dim(feature)[1]){
    print(sum(is.na(feature[line,])))
  }
}
```

###NA imputing
#Delete the feature if number of NA is larger than x
```{r, warning=FALSE, message=FALSE}
Delete_NA <- function(feature, delete_range){
  feature_id = 1
  while (feature_id <= dim(feature)[2]) {
    if (sum(is.na(feature[1:80,feature_id])) > delete_range){
      feature <- feature[,-feature_id]
    } else {
      feature_id = feature_id + 1
    }
  }
  return(feature)
}
```

#Rrplace all NA to 0
```{r, warning=FALSE, message=FALSE}
Replace_0 <- function(feature){
  feature[is.na(feature)]=0
  return(feature)
}
```

#Rrplace all NA to the mean of the column
```{r, warning=FALSE, message=FALSE}
Replace_mean <- function(feature, correct_size){
  feature = Replace_0(feature)
  for (col in 1:dim(feature)[2]){
    if(sum(feature[,col])!=0) {
      feature_mean = sum(feature[1:correct_size,col])/(length(feature[1:correct_size,col])-sum(feature[1:correct_size,col] == 0))
    } else {
      feature_mean = 0
    }
    for (i in 1:length(feature[,col])){
      if ((feature[i,col])==0){
        feature[i,col] = feature_mean
      }
    }
  }
  return(feature)
}
```

#Feature imputing by correlation cofficient
```{r, warning=FALSE, message=FALSE}
Feature_cor_test <- function(feature, datacli, at_most_na = 60){
  feature_all = data.frame(co_gender = numeric(dim(feature)[2]),
                       co_msi = numeric(dim(feature)[2]),
                       num_na = numeric(dim(feature)[2]))
  feature_gender.pvalues <- c()
  feature_msi.pvalues <- c()
  feature_id = 1
  while (feature_id <= dim(feature)[2]) {
    if (sum(is.na(feature[,feature_id])) > 0 && sum(is.na(feature[,feature_id])) < at_most_na){
      empty_feature = as.numeric(which(is.na(feature[,feature_id])))
      p_gender = cor.test(feature[-empty_feature, feature_id], datacli[-empty_feature, 1], method = "pearson")$estimate
      feature_all[feature_id, 1] = abs(p_gender)
      p_msi = cor.test(feature[-empty_feature, feature_id], datacli[-empty_feature, 2], method = "pearson")$estimate
      feature_all[feature_id, 2] = abs(p_msi)
      feature_all[feature_id, 3] = sum(is.na(feature[,feature_id]))
    } else if(sum(is.na(feature[,feature_id])) == 0) {
      p_gender = cor.test(feature[, feature_id], datacli[, 1], method = "pearson")$estimate
      feature_all[feature_id, 1] = abs(p_gender)
      p_msi = cor.test(feature[, feature_id], datacli[, 2], method = "pearson")$estimate
      feature_all[feature_id, 2] = abs(p_msi)
      feature_all[feature_id, 3] = sum(is.na(feature[,feature_id]))
    } else {
      feature_all[feature_id, 1] = 0
      feature_all[feature_id, 2] = 0
      feature_all[feature_id, 3] = sum(is.na(feature[,feature_id]))
    }
    feature_id = feature_id + 1
  }
  rownames(feature_all) = colnames(feature)
  return(feature_all)
}

# Build dataset after cor test by inpute Mean or zero
Build_dataset_cor <- function(feature, select_featuer_names, correct_size, imputeMean = 1){
  feature = Replace_0(feature)
  correct_pro = feature[1:correct_size, select_featuer_names]
  select_feature = feature[, select_featuer_names]
  for (col in 1:dim(correct_pro)[2]){
    if(imputeMean == 1){
      impute = sum(correct_pro[,col])/(length(correct_pro[,col])-sum(correct_pro[,col] == 0))
    } else {
      impute = 0
    }
    for (i in 1:length(select_feature[,col])){
      if ((select_feature[i,col])==0){
        select_feature[i,col] = impute
      }
    }
  }
  return(select_feature)
}
```

###Train label restructure
#Transform gender and MSI
```{r, warning=FALSE, message=FALSE}
Cli_transform <- function(cli){
  new_cli = data.frame(isMale = numeric(dim(cli)[1]),
                       isMSI_High = numeric(dim(cli)[1]))
  for (line in 1:dim(cli)[1]){
    if (cli[line,2] == 'Male'){
      new_cli[line,1] = 1
    }
    if (cli[line,3] == 'MSI-High'){
      new_cli[line,2] = 1
    }
  }
  return(new_cli)
}
train_cli = Cli_transform(train_cli)
test_cli = Cli_transform(test_cli)

Build_correct_set <- function(data_set, is_correcrt_label, collect = 0){
  for (line in dim(is_correcrt_label)[1]:1){
    if (is_correcrt_label[line,2] == collect){
      data_set = data_set[-line,]
    }
  }
  return(data_set)
}
```

###Up sampling
```{r, warning=FALSE, message=FALSE}
Up_sanmpling <- function(feature, cli){
  new_cli = c()
  for(line in 1:dim(cli)[1]){
    if(cli[line,1] == 0){
      if(cli[line,2] == 0){
        new_cli = c(new_cli, 0)
      } else{
        new_cli = c(new_cli, 1)
      }
    }else if(cli[line,1] == 1){
      if(cli[line,2] == 0){
        new_cli = c(new_cli, 2)
      } else{
        new_cli = c(new_cli, 3)
      }
    }
  }
  
  most_label = max(sum(new_cli==0), sum(new_cli==1), sum(new_cli==2), sum(new_cli==3))
  feature = cbind(feature, cli)
  new_feature = data.frame()
  for(i in 0:3){
    if(most_label/sum(new_cli==i)>=1){
      for (o in 1:(most_label%/%sum(new_cli==i))){
        new_feature = rbind(new_feature, feature[as.numeric(which(new_cli == i)),])
      }
    }
    if((most_label%%sum(new_cli==i))>0){
      new_feature = rbind(new_feature, feature[as.numeric(which(new_cli == i)),][1:(most_label%%sum(new_cli==i)),])
    }
  }
  return(new_feature)
}
```

###Feature scaling

#Min-max scaling
```{r, warning=FALSE, message=FALSE}
Min_max_scaling <- function(feature){
  return((feature-min(feature))/(max(feature)-min(feature)))
}
```

###Feature Selection and decomposition
#Fold change
```{r, warning=FALSE, message=FALSE}
Fold_change <- function(train_data, train_answer, test_data, feature_num){
  DataTrain.byClass <- split(train_data, train_answer)
  feature.mean.byClass <- sapply(DataTrain.byClass, colMeans)
  feature.foldChange <- abs(log2(feature.mean.byClass[,1] / feature.mean.byClass[,2]))
  feature.sorted <- sort(feature.foldChange, decreasing=TRUE)
  filtered.features <- names(feature.sorted)[1:feature_num]
  return(filtered.features)
}
Build_dataset <- function(dataset, features){
  return (dataset[,features])
}
```

#PCA
```{r, warning=FALSE, message=FALSE}
PCA <- function(datapro, n_factors){
  pca <- principal(t(datapro),nfactors=n_factors,rotate="none", score=TRUE)
  return(pca)
}
```

###Model testing
#KNN
```{r, warning=FALSE, message=FALSE}
Knn_approach_CV <- function(train_data_gender, train_data_msi, train_cli, k=1){
  set.seed(1)
  fold <- createFolds(train_cli[,1], k=10)
  gender.TP <- gender.TN <- gender.FP <- gender.FN <- c()
  msi.TP <- msi.TN <- msi.FP <- msi.FN <- c()
  num_test = 0
  num_correct = 0
  for(i in 1:length(fold)){
    # true label for fold i
    truth_gender <- train_cli[fold[[i]],1]
    truth_msi <- train_cli[fold[[i]],2]
    preds_gender <- knn(train_data_gender[-fold[[i]],], train_data_gender[fold[[i]],],train_cli[-fold[[i]],1], k=k)
    gender.TP <- c(gender.TP, sum((truth_gender == preds_gender)[truth_gender == 1]))
    gender.TN <- c(gender.TN, sum((truth_gender == preds_gender)[truth_gender == 0]))
    gender.FP <- c(gender.FP, sum((truth_gender != preds_gender)[truth_gender == 0]))
    gender.FN <- c(gender.FN, sum((truth_gender != preds_gender)[truth_gender == 1]))
    preds_msi <- knn(train_data_msi[-fold[[i]],], train_data_msi[fold[[i]],],train_cli[-fold[[i]],2], k=k)
    msi.TP <- c(msi.TP, sum((truth_msi == preds_msi)[truth_msi == 1]))
    msi.TN <- c(msi.TN, sum((truth_msi == preds_msi)[truth_msi == 0]))
    msi.FP <- c(msi.FP, sum((truth_msi != preds_msi)[truth_msi == 0]))
    msi.FN <- c(msi.FN, sum((truth_msi != preds_msi)[truth_msi == 1]))
    for (check in 1:length(truth_gender)){
      num_test = num_test +1
      if (preds_gender[check] == truth_gender[check] && preds_msi[check] == truth_msi[check]){
        num_correct = num_correct +1
      }
    }
  }
  gender_measures = evaluate(gender.TN, gender.FP, gender.TP, gender.FN)
  msi_measures = evaluate(msi.TN, msi.FP, msi.TP, msi.FN)
  paste('KNN 10-Fold CV Accuracy:', num_correct/num_test)
  return(c(num_correct/num_test, gender_measures, msi_measures))
}
```

#Logistic Regression
```{r, warning=FALSE, message=FALSE}
Logreg_approach_CV <- function(train_data_gender, train_data_msi, train_cli){
  set.seed(1)
  fold <- createFolds(train_cli[,1], k=10)
  gender.TP <- gender.TN <- gender.FP <- gender.FN <- c()
  msi.TP <- msi.TN <- msi.FP <- msi.FN <- c()
  num_test = 0
  num_correct = 0
  train_data_gender = as.data.frame(train_data_gender)
  train_data_gender$label = train_cli[,1]
  train_data_msi = as.data.frame(train_data_msi)
  train_data_msi$label = train_cli[,2]
  for (i in 1:length(fold)) {
    truth_gender <- train_cli[fold[[i]],1]
    truth_msi <- train_cli[fold[[i]],2]
    
    glm_gender <- glm(label~., data=train_data_gender[-fold[[i]],])
    preds_gender <- predict(glm_gender, train_data_gender[fold[[i]],])
    preds_gender <- ifelse(preds_gender > 0.5, 1, 0)
    gender.TP <- c(gender.TP, sum((truth_gender == preds_gender)[truth_gender == 1]))
    gender.TN <- c(gender.TN, sum((truth_gender == preds_gender)[truth_gender == 0]))
    gender.FP <- c(gender.FP, sum((truth_gender != preds_gender)[truth_gender == 0]))
    gender.FN <- c(gender.FN, sum((truth_gender != preds_gender)[truth_gender == 1]))
    
    glm_msi <- glm(label~., data=train_data_msi[-fold[[i]],])
    preds_msi <- predict(glm_msi, train_data_msi[fold[[i]],])
    preds_msi <- ifelse(preds_msi > 0.5, 1, 0)
    msi.TP <- c(msi.TP, sum((truth_msi == preds_msi)[truth_msi == 1]))
    msi.TN <- c(msi.TN, sum((truth_msi == preds_msi)[truth_msi == 0]))
    msi.FP <- c(msi.FP, sum((truth_msi != preds_msi)[truth_msi == 0]))
    msi.FN <- c(msi.FN, sum((truth_msi != preds_msi)[truth_msi == 1]))
    
    for (check in 1:length(truth_gender)){
      num_test = num_test +1
      if (preds_gender[check] == truth_gender[check] && preds_msi[check] == truth_msi[check]){
        num_correct = num_correct +1
      }
    }
  }
  gender_measures = evaluate(gender.TN, gender.FP, gender.TP, gender.FN)
  msi_measures = evaluate(msi.TN, msi.FP, msi.TP, msi.FN)
  paste('Logistic Regression 10-Fold CV Accuracy:', num_correct/num_test)
  return(c(num_correct/num_test, gender_measures, msi_measures))
}
```

#AdaBoost
```{r, warning=FALSE, message=FALSE}
AdaBoost_approach_CV <- function(correct_label_data_gender, correct_label_data_msi, correct_label_cli, n.trees = 103){
  set.seed(1)
  fold <- createFolds(correct_label_cli[,1], k=10)
  gender.TP <- gender.TN <- gender.FP <- gender.FN <- c()
  msi.TP <- msi.TN <- msi.FP <- msi.FN <- c()
  num_test = 0
  num_correct = 0
  
  train_data_gender = as.data.frame(correct_label_data_gender)
  train_data_gender$label = correct_label_cli[,1]
  train_data_msi = as.data.frame(correct_label_data_msi)
  train_data_msi$label = correct_label_cli[,2]
  for (i in 1:length(fold)) {
    truth_gender <- correct_label_cli[fold[[i]],1]
    truth_msi <- correct_label_cli[fold[[i]],2]
    
    adaBoost_gender.model <- gbm(label~., data=train_data_gender[-fold[[i]],], distribution="adaboost", n.trees=n.trees)
    preds_gender <- predict(adaBoost_gender.model, newdata = train_data_gender[fold[[i]],], n.trees=n.trees, type="response")
    preds_gender <- ifelse(preds_gender > 0.5, 1, 0)
    gender.TP <- c(gender.TP, sum((truth_gender == preds_gender)[truth_gender == 1]))
    gender.TN <- c(gender.TN, sum((truth_gender == preds_gender)[truth_gender == 0]))
    gender.FP <- c(gender.FP, sum((truth_gender != preds_gender)[truth_gender == 0]))
    gender.FN <- c(gender.FN, sum((truth_gender != preds_gender)[truth_gender == 1]))
    
    adaBoost_msi.model <- gbm(label~., data=train_data_msi[-fold[[i]],], distribution="adaboost", n.trees=n.trees)
    preds_msi <- predict(adaBoost_msi.model, newdata = train_data_msi[fold[[i]],], n.trees=n.trees, type="response")
    preds_msi <- ifelse(preds_msi > 0.5, 1, 0)
    msi.TP <- c(msi.TP, sum((truth_msi == preds_msi)[truth_msi == 1]))
    msi.TN <- c(msi.TN, sum((truth_msi == preds_msi)[truth_msi == 0]))
    msi.FP <- c(msi.FP, sum((truth_msi != preds_msi)[truth_msi == 0]))
    msi.FN <- c(msi.FN, sum((truth_msi != preds_msi)[truth_msi == 1]))
    
    for (check in 1:length(truth_gender)){
      num_test = num_test +1
      if (preds_gender[check] == truth_gender[check] && preds_msi[check] == truth_msi[check]){
        num_correct = num_correct +1
      }
    }
  }
  gender_measures = evaluate(gender.TN, gender.FP, gender.TP, gender.FN)
  msi_measures = evaluate(msi.TN, msi.FP, msi.TP, msi.FN)
  paste('AdaBoost 10-Fold CV Accuracy:', num_correct/num_test)
  return(c(num_correct/num_test, gender_measures, msi_measures))
}
```

###Grid Search
```{r, warning=FALSE, message=FALSE}
KNN_grid_search_normal<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  pca_list = c(10, 20, 40, 60, 80)
  k_list = c(1, 3, 5, 7)
  rows = length(pca_list) * length(k_list)
  result = data.frame(PCA = numeric(rows),
                      K = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (pca in pca_list){
    correct_label_data_gender = correct_label_data_msi = PCA(correct_label_pro, pca)$weights[1:correct_label_pro_size,]
    for (k in k_list){
      acc = Knn_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli, k = k)
      result[row_pos, 1]=pca
      result[row_pos, 2]=k
      for (i in 3:13){
        result[row_pos, i]=acc[i-2]
      }
      row_pos = row_pos + 1
    }
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Logreg_grid_search_normal<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  pca_list = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 60, 80)
  rows = length(pca_list)
  result = data.frame(PCA = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (pca in pca_list){
    correct_label_data_gender = correct_label_data_msi = PCA(correct_label_pro, pca)$weights[1:correct_label_pro_size,]
    acc = Logreg_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)
    result[row_pos, 1]=pca
    for (i in 2:12){
      result[row_pos, i]=acc[i-1]
    }
    row_pos = row_pos + 1
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Adaboost_grid_search_normal<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  pca_list = c(10, 20, 40, 60, 80)
  n.trees = c(20, 40, 80, 100, 150, 200)
  rows = length(pca_list) * length(n.trees)
  result = data.frame(PCA = numeric(rows),
                      n_trees = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (pca in pca_list){
    correct_label_data_gender = correct_label_data_msi = PCA(correct_label_pro, pca)$weights[1:correct_label_pro_size,]
    for (n in n.trees){
      acc = AdaBoost_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli, n.trees = n)
      result[row_pos, 1]=pca
      result[row_pos, 2]=n
      for (i in 3:13){
        result[row_pos, i]=acc[i-2]
      }
      row_pos = row_pos + 1
    }
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
KNN_grid_search_cor<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  feature_select_num = c(20, 60, 100, 140, 180)
  pca_list = c(5, 10, 15, 20)
  k_list = c(1, 3, 5, 7)
  rows = length(pca_list) * length(k_list) * length(feature_select_num)
  result = data.frame(num_feature = numeric(rows),
                      PCA = numeric(rows),
                      K = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (fn in feature_select_num){
    feature_summary = Feature_cor_test(correct_label_pro[1:correct_label_pro_size,], correct_label_cli[1:correct_label_pro_size,])
    feature_select_gender = row.names(feature_summary[order(feature_summary[,1], decreasing = T)[1:fn],])
    feature_select_msi = row.names(feature_summary[order(feature_summary[,2], decreasing = T)[1:fn],])
    all_train_data_gender = Build_dataset_cor(correct_label_pro, feature_select_gender, correct_label_pro_size, imputeMean = 1)
    all_train_data_msi= Build_dataset_cor(correct_label_pro, feature_select_msi, correct_label_pro_size, imputeMean = 1)
    for (pca in pca_list){
      correct_label_data_gender = PCA(all_train_data_gender, pca)$weights[1:correct_label_pro_size,]
      correct_label_data_msi = PCA(all_train_data_msi, pca)$weights[1:correct_label_pro_size,]
      for (k in k_list){
        acc = Knn_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli, k = k)
        result[row_pos, 1]=fn
        result[row_pos, 2]=pca
        result[row_pos, 3]=k
        for (i in 4:14){
          result[row_pos, i]=acc[i-3]
        }
        row_pos = row_pos + 1
      }
    }
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Logreg_grid_search_cor<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  feature_select_num = c(20, 60, 100, 140, 180)
  pca_list = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 60, 80)
  rows = length(pca_list)
  result = data.frame(num_feature = numeric(rows),
                      PCA = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (fn in feature_select_num){
    feature_summary = Feature_cor_test(correct_label_pro[1:correct_label_pro_size,], correct_label_cli[1:correct_label_pro_size,])
    feature_select_gender = row.names(feature_summary[order(feature_summary[,1], decreasing = T)[1:fn],])
    feature_select_msi = row.names(feature_summary[order(feature_summary[,2], decreasing = T)[1:fn],])
    all_train_data_gender = Build_dataset_cor(correct_label_pro, feature_select_gender, correct_label_pro_size, imputeMean = 1)
    all_train_data_msi= Build_dataset_cor(correct_label_pro, feature_select_msi, correct_label_pro_size, imputeMean = 1)
    for (pca in pca_list){
      correct_label_data_gender = PCA(all_train_data_gender, pca)$weights[1:correct_label_pro_size,]
      correct_label_data_msi = PCA(all_train_data_msi, pca)$weights[1:correct_label_pro_size,]
      acc = Logreg_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)
      result[row_pos, 1]=fn
      result[row_pos, 2]=pca
      for (i in 3:13){
        result[row_pos, i]=acc[i-2]
      }
      row_pos = row_pos + 1
    }
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Adaboost_grid_search_cor<- function(correct_label_pro, correct_label_cli, correct_label_pro_size){
  feature_select_num = c(20, 60, 100, 140, 180)
  pca_list = c(10, 20, 40, 60, 80)
  n.trees = c(20, 40, 80, 100, 150, 200)
  rows = length(pca_list)
  result = data.frame(num_feature = numeric(rows),
                      PCA = numeric(rows),
                      n_trees = numeric(rows),
                      total_acc = numeric(rows),
                      gender_sen = numeric(rows),
                      gender_spe = numeric(rows),
                      gender_f1 = numeric(rows),
                      gender_gmean = numeric(rows),
                      gender_acc = numeric(rows),
                      msi_sen = numeric(rows),
                      msi_spe = numeric(rows),
                      msi_f1 = numeric(rows),
                      msi_gmean = numeric(rows),
                      msi_acc = numeric(rows))
  row_pos = 1
  paste("With out up sampling, not using correlation cofficient")
  for (fn in feature_select_num){
    feature_summary = Feature_cor_test(correct_label_pro[1:correct_label_pro_size,], correct_label_cli[1:correct_label_pro_size,])
    feature_select_gender = row.names(feature_summary[order(feature_summary[,1], decreasing = T)[1:fn],])
    feature_select_msi = row.names(feature_summary[order(feature_summary[,2], decreasing = T)[1:fn],])
    all_train_data_gender = Build_dataset_cor(correct_label_pro, feature_select_gender, correct_label_pro_size, imputeMean = 1)
    all_train_data_msi= Build_dataset_cor(correct_label_pro, feature_select_msi, correct_label_pro_size, imputeMean = 1)
    for (pca in pca_list){
      correct_label_data_gender = PCA(all_train_data_gender, pca)$weights[1:correct_label_pro_size,]
      correct_label_data_msi = PCA(all_train_data_msi, pca)$weights[1:correct_label_pro_size,]
      acc = Logreg_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)
      correct_label_data_gender = correct_label_data_msi = PCA(correct_label_pro, pca)$weights[1:correct_label_pro_size,]
      for (n in n.trees){
        acc = AdaBoost_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli, n.trees = n)
        result[row_pos, 1]=fn
        result[row_pos, 2]=pca
        result[row_pos, 3]=n
        for (i in 4:14){
          result[row_pos, i]=acc[i-3]
        }
        row_pos = row_pos + 1
      }
    }
  }
  return(result)
}
```

###Train
```{r, warning=FALSE, message=FALSE}
AdaBoost_approach<- function(correct_label_data_gender, correct_label_data_msi, test_label_data_gender, test_label_data_msi, correct_label_cli, n.trees = 200){
  train_data_gender = as.data.frame(correct_label_data_gender)
  train_data_gender$label = correct_label_cli[,1]
  train_data_msi = as.data.frame(correct_label_data_msi)
  train_data_msi$label = correct_label_cli[,2]
  test_data_gender = as.data.frame(test_label_data_gender)
  test_data_msi = as.data.frame(test_label_data_msi)
    
  adaBoost_gender.model <- gbm(label~., data=train_data_gender, distribution="adaboost", n.trees=n.trees)
  preds_gender <- predict(adaBoost_gender.model, newdata = test_data_gender, n.trees=n.trees, type="response")
  
  adaBoost_msi.model <- gbm(label~., data=train_data_msi, distribution="adaboost", n.trees=n.trees)
  preds_msi <- predict(adaBoost_msi.model, newdata = test_data_msi, n.trees=n.trees, type="response")
  result = data.frame(isMale = preds_gender,
                       isMSI_High = preds_msi)
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Logreg_approach<- function(correct_label_data_gender, correct_label_data_msi, test_label_data_gender, test_label_data_msi, correct_label_cli){
  train_data_gender = as.data.frame(correct_label_data_gender)
  train_data_gender$label = correct_label_cli[,1]
  train_data_msi = as.data.frame(correct_label_data_msi)
  train_data_msi$label = correct_label_cli[,2]
  test_data_gender = as.data.frame(test_label_data_gender)
  test_data_msi = as.data.frame(test_label_data_msi)
    
  glm_gender <- glm(label~., data=train_data_gender)
  preds_gender <- predict(glm_gender, test_data_gender)
  
  glm_msi <- glm(label~., data=train_data_msi)
  preds_msi <- predict(glm_msi, test_data_msi)
  result = data.frame(isMale = preds_gender,
                       isMSI_High = preds_msi)
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
Knn_approach<- function(correct_label_data_gender, correct_label_data_msi, test_label_data_gender, test_label_data_msi, correct_label_cli, k=1){
  preds_gender <- knn(correct_label_data_gender, test_label_data_gender, correct_label_cli[,1], k=k)
  preds_msi <- knn(correct_label_data_msi, test_label_data_msi, correct_label_cli[,2], k=k)
  result = data.frame(isMale = preds_gender,
                       isMSI_High = preds_msi)
  return(result)
}
```

#AdaSampling
```{r, warning=FALSE, message=FALSE}
AdaSampling_approach <- function(train_data_gender, train_data_msi, mis_label_data_gender, mis_label_data_msi, train_cli, c = 50){
  cls_gender <- train_cli[,1]
  cls_msi <- train_cli[,2]
  # index positive and negative instances
  Ps_gender <- rownames(train_data_gender)[which(cls_gender == 1)]
  Ns_gender <- rownames(train_data_gender)[which(cls_gender == 0)]
  Ns_gender <- c(Ns_gender, rownames(mis_label_data_gender))
  Ps_msi <- rownames(train_data_msi)[which(cls_msi == 1)]
  Ns_msi <- rownames(train_data_msi)[which(cls_msi == 0)]
  Ns_msi <- c(Ns_msi, rownames(mis_label_data_msi))
  preds_gender <- adaSample(Ps_gender, Ns_gender, rbind(train_data_gender, mis_label_data_gender), mis_label_data_gender, classifier="svm", C=c)

  preds_msi <- adaSample(Ps_msi, Ns_msi, rbind(train_data_msi, mis_label_data_msi), mis_label_data_msi, classifier="svm", C=c)
  result = data.frame(isMale = preds_gender[,1],
                       isMSI_High = preds_msi[,1])
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
is_mislabel<- function(predict_result, answer){
  predict_result <- ifelse(predict_result > 0.5, 1, 0)
  result = c()
  for (line in 1:dim(predict_result)[1]){
    if (predict_result[line, 1] == answer[line, 1] && predict_result[line, 2] == answer[line, 2]){
      result = c(result, 0)
    } else {
      result = c(result, 1)
    }
  }
  return(result)
}
```

```{r, warning=FALSE, message=FALSE}
is_mislabel_knn<- function(predict_result, answer){
  result = c()
  for (line in 1:dim(predict_result)[1]){
    if (predict_result[line, 1] == answer[line, 1] && predict_result[line, 2] == answer[line, 2]){
      result = c(result, 0)
    } else {
      result = c(result, 1)
    }
  }
  return(result)
}
```

###Grid search main
```{r, warning=FALSE, message=FALSE}
correct_label_cli = Build_correct_set(train_cli, is_correcrt_label, 1)
correct_label_pro = Build_correct_set(train_pro, is_correcrt_label, 1)
mis_label_cli = Build_correct_set(train_cli, is_correcrt_label, 0)
mis_label_data = Build_correct_set(train_pro, is_correcrt_label, 0)
mis_label_data_size = dim(mis_label_data)[1]

######## Normal approach grid search with out up sampling, without feature less than 50 NA value, replace NA by mean
print("Normal approach grid search with out up sampling, without feature less than 50 NA value, replace NA by mean")
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Delete_NA(alldata_pro, 50)
datapro = Replace_mean(datapro, correct_label_pro_size)
datapro = Min_max_scaling(datapro)

oneset_noups_knn_result_delNA_mean = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_knn_result_delNA_mean
oneset_noups_logreg_result_delNA_mean = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_logreg_result_delNA_mean
oneset_noups_adaboost_result_delNA_mean = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_adaboost_result_delNA_mean

######## Normal approach grid search with out up sampling, with all data, replace NA by 0
print("Normal approach grid search with out up sampling, with all data, replace NA by 0")
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Replace_0(alldata_pro)
datapro = Min_max_scaling(datapro)

oneset_noups_knn_result_0 = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_knn_result_0
oneset_noups_logreg_result_0 = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_logreg_result_0
oneset_noups_adaboost_result_0 = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_adaboost_result_0

######## Normal approach grid search with out up sampling, without feature less than 50 NA value, replace NA by 0
print("Normal approach grid search with out up sampling, without feature less than 50 NA value, replace NA by 0")
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Delete_NA(alldata_pro, 50)
datapro = Replace_0(datapro)
datapro = Min_max_scaling(datapro)

oneset_noups_knn_result_delNA_0 = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_knn_result_delNA_0
oneset_noups_logreg_result_delNA_0 = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_logreg_result_delNA_0
oneset_noups_adaboost_result_delNA_0 = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_noups_adaboost_result_delNA_0

######## Cor test approach grid search with out up sampling
print("Cor test approach grid search with out up sampling")
twoset_noups_knn_result = KNN_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_noups_knn_result
twoset_noups_logreg_result = Logreg_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_noups_logreg_result
twoset_noups_adaboost_result = Adaboost_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_noups_adaboost_result

######## Normal approach grid search with up sampling, without feature less than 50 NA value, replace NA by mean
print("Normal approach grid search with up sampling, without feature less than 50 NA value, replace NA by mean")
correct_label_pro_cli = Up_sanmpling(correct_label_pro, correct_label_cli)
correct_label_cli = correct_label_pro_cli[,c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro = correct_label_pro_cli[,-c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Delete_NA(alldata_pro, 50)
datapro = Replace_mean(datapro, correct_label_pro_size)
datapro = Min_max_scaling(datapro)

oneset_ups_knn_result_delNA = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_knn_result_delNA
oneset_ups_logreg_result_delNA = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_logreg_result_delNA
oneset_ups_adaboost_result_delNA = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_adaboost_result_delNA

######## Normal approach grid search with up sampling, with all data, replace NA by 0
print("Normal approach grid search with up sampling, with all data, replace NA by 0")
correct_label_pro_cli = Up_sanmpling(correct_label_pro, correct_label_cli)
correct_label_cli = correct_label_pro_cli[,c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro = correct_label_pro_cli[,-c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Replace_0(alldata_pro)
datapro = Min_max_scaling(datapro)

oneset_ups_knn_result = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_knn_result
oneset_ups_logreg_result = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_logreg_result
oneset_ups_adaboost_result = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_adaboost_result

######## Normal approach grid search with up sampling, without feature less than 50 NA value, replace NA by 0
print("Normal approach grid search with up sampling, without feature less than 50 NA value, replace NA by 0")
correct_label_pro_cli = Up_sanmpling(correct_label_pro, correct_label_cli)
correct_label_cli = correct_label_pro_cli[,c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro = correct_label_pro_cli[,-c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro_size = dim(correct_label_pro)[1]
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)
datapro = Delete_NA(alldata_pro, 50)
datapro = Replace_0(datapro)
datapro = Min_max_scaling(datapro)

oneset_ups_knn_result_delNA = KNN_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_knn_result_delNA
oneset_ups_logreg_result_delNA = Logreg_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_logreg_result_delNA
oneset_ups_adaboost_result_delNA = Adaboost_grid_search_normal(datapro, correct_label_cli, correct_label_pro_size)
oneset_ups_adaboost_result_delNA

######## Cor test approach grid search with up sampling
print("Cor test approach grid search with up sampling")
twoset_ups_knn_result = KNN_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_ups_knn_result
twoset_ups_logreg_result = Logreg_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_ups_logreg_result
twoset_ups_adaboost_result = Adaboost_grid_search_cor(datapro, correct_label_cli, correct_label_pro_size)
twoset_ups_adaboost_result
```

###Train Main
```{r, warning=FALSE, message=FALSE}
correct_label_cli = Build_correct_set(train_cli, is_correcrt_label, 1)
correct_label_pro = Build_correct_set(train_pro, is_correcrt_label, 1)
mis_label_cli = Build_correct_set(train_cli, is_correcrt_label, 0)
mis_label_data = Build_correct_set(train_pro, is_correcrt_label, 0)
mis_label_data_size = dim(mis_label_data)[1]

######## Up sampling
correct_label_pro_cli = Up_sanmpling(correct_label_pro, correct_label_cli)
correct_label_cli = correct_label_pro_cli[,c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
correct_label_pro = correct_label_pro_cli[,-c(dim(correct_label_pro_cli)[2], dim(correct_label_pro_cli)[2]-1)]
########

######## Cor test approach
correct_label_pro_size = dim(correct_label_pro)[1]
feature_summary = Feature_cor_test(correct_label_pro, correct_label_cli)
feature_select_gender = row.names(feature_summary[order(feature_summary[,1], decreasing = T)[1:100],])
feature_select_msi = row.names(feature_summary[order(feature_summary[,2], decreasing = T)[1:100],])
alldata_pro = rbind(correct_label_pro, mis_label_data, test_pro)

all_train_data_gender = Build_dataset_cor(alldata_pro, feature_select_gender, correct_label_pro_size, imputeMean = 1)
all_train_data_msi= Build_dataset_cor(alldata_pro, feature_select_msi, correct_label_pro_size, imputeMean = 1)
correct_label_pro_size = dim(correct_label_pro)[1]

all_train_data_gender = Min_max_scaling(all_train_data_gender)
all_train_data_msi = Min_max_scaling(all_train_data_msi)
all_train_data_gender = PCA(all_train_data_gender, 10)$weights
all_train_data_msi = PCA(all_train_data_msi, 10)$weights

correct_label_data_gender = all_train_data_gender[1:correct_label_pro_size,]
correct_label_data_msi = all_train_data_msi[1:correct_label_pro_size,]
mis_label_data_gender = all_train_data_gender[(correct_label_pro_size+1):(correct_label_pro_size+mis_label_data_size),]
mis_label_data_msi = all_train_data_msi[(correct_label_pro_size+1):(correct_label_pro_size+mis_label_data_size),]
test_data_gender = all_train_data_gender[(correct_label_pro_size+mis_label_data_size+1):(correct_label_pro_size+mis_label_data_size+80),]
test_data_msi = all_train_data_msi[(correct_label_pro_size+mis_label_data_size+1):(correct_label_pro_size+mis_label_data_size+80),]

# Try KNN
Knn_measures = Knn_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)

correct_label_preds = Knn_approach(correct_label_data_gender, correct_label_data_msi,correct_label_data_gender, correct_label_data_msi, correct_label_cli)
correct_label_result = is_mislabel_knn(correct_label_preds, correct_label_cli)
correct_label_accuracy = sum(correct_label_result == 0)/length(correct_label_result)
print('KNN test on correct label set')
print(correct_label_accuracy)

mis_label_preds = Knn_approach(correct_label_data_gender, correct_label_data_msi,mis_label_data_gender, mis_label_data_msi, correct_label_cli)
mis_label_result = is_mislabel_knn(mis_label_preds, mis_label_cli)
mis_label_accuracy = sum(mis_label_result == 1)/length(mis_label_result)
print('KNN test on mislabel set')
print(mis_label_accuracy)

knn_test_result = Knn_approach(correct_label_data_gender, correct_label_data_msi,test_data_gender, test_data_msi, correct_label_cli)
knn_test_result

# Try AdaBoost
AdaBoost_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)

correct_label_preds = AdaBoost_approach(correct_label_data_gender, correct_label_data_msi,correct_label_data_gender, correct_label_data_msi, correct_label_cli)
correct_label_result = is_mislabel(correct_label_preds, correct_label_cli)
correct_label_accuracy = sum(correct_label_result == 0)/length(correct_label_result)
print('AdaBoost test on correct label set')
print(correct_label_accuracy)

mis_label_preds = AdaBoost_approach(correct_label_data_gender, correct_label_data_msi,mis_label_data_gender, mis_label_data_msi, correct_label_cli)
mis_label_result = is_mislabel(mis_label_preds, mis_label_cli)
mis_label_accuracy = sum(mis_label_result == 1)/length(mis_label_result)
print('AdaBoost test on mislabel set')
print(mis_label_accuracy)

adaboost_test_result = AdaBoost_approach(correct_label_data_gender, correct_label_data_msi,test_data_gender, test_data_msi, correct_label_cli)
adaboost_test_result

# Try Logestic Regression
Logreg_approach_CV(correct_label_data_gender, correct_label_data_msi, correct_label_cli)

correct_label_preds = Logreg_approach(correct_label_data_gender, correct_label_data_msi,correct_label_data_gender, correct_label_data_msi, correct_label_cli)
correct_label_result = is_mislabel(correct_label_preds, correct_label_cli)
correct_label_accuracy = sum(correct_label_result == 0)/length(correct_label_result)
print('Logestic Regression test on correct label set')
print(correct_label_accuracy)

mis_label_preds = Logreg_approach(correct_label_data_gender, correct_label_data_msi,mis_label_data_gender, mis_label_data_msi, correct_label_cli)
mis_label_result = is_mislabel(mis_label_preds, mis_label_cli)
mis_label_accuracy = sum(mis_label_result == 1)/length(mis_label_result)
print('Logestic Regression test on mislabel set')
print(mis_label_accuracy)

logreg_test_result = Logreg_approach(correct_label_data_gender, correct_label_data_msi,test_data_gender, test_data_msi, correct_label_cli)
logreg_test_result

# Try Adasampling
correct_label_preds = AdaSampling_approach(correct_label_data_gender, correct_label_data_msi,correct_label_data_gender, correct_label_data_msi, correct_label_cli)
correct_label_result = is_mislabel(correct_label_preds, correct_label_cli)
correct_label_accuracy = sum(correct_label_result == 0)/length(correct_label_result)
print('Adasampling test on correct label set')
print(correct_label_accuracy)

mis_label_preds = AdaSampling_approach(correct_label_data_gender, correct_label_data_msi,mis_label_data_gender, mis_label_data_msi, correct_label_cli)
mis_label_result = is_mislabel(mis_label_preds, mis_label_cli)
mis_label_accuracy = sum(mis_label_result == 1)/length(mis_label_result)
print('Adasampling test on mislabel set')
print(mis_label_accuracy)

adasamp_test_result = AdaSampling_approach(correct_label_data_gender, correct_label_data_msi,test_data_gender, test_data_msi, correct_label_cli)
adasamp_test_result
```

